{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMflxPzkad8phiWePahhd4y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwisetree/AIFFEL_quest_cr/blob/main/Python/DataAnalysis_Python_LMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6-1. 프로젝트 (1) load_digits : 손글씨를 분류해 봅시다"
      ],
      "metadata": {
        "id": "HgNnvhQTKh6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##1. 필요한 모듈 import하기\n",
        "##2. 데이터 준비\n",
        "##3. 데이터 이해하기\n",
        "##4. train, test 데이터 분리\n",
        "##5. 다양한 모델로 학습시켜보기\n",
        "##6. 모델을 평가해 보기"
      ],
      "metadata": {
        "id": "lnBznCh7KuXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6g46GnwiJ3Uf"
      },
      "outputs": [],
      "source": [
        "##1. 필요한 모듈 import하기\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##2. 데이터 준비\n",
        "\n",
        "# load_digits로 데이터셋 불러오기\n",
        "digits = load_digits()\n",
        "\n",
        "# 데이터셋 내용 보기\n",
        "print(digits.data.shape)  # (1797, 64): 1797개의 샘플, 각 샘플은 64개의 특성(8x8 이미지 크기)\n",
        "print(digits.target_names)  # 0~9까지의 숫자"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8LgHevhJ7wu",
        "outputId": "9be86c99-8d28-4f38-a48c-ea5afc876273"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n",
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##3. 데이터 이해하기\n",
        "\n",
        "# Feature Data: 숫자 이미지를 64개의 픽셀 값으로 표현한 데이터\n",
        "X = digits.data\n",
        "\n",
        "# Label Data: 각 숫자 이미지에 해당하는 레이블 (0~9)\n",
        "y = digits.target\n",
        "\n",
        "# Target Names 출력하기\n",
        "print(\"Target Names:\", digits.target_names)\n",
        "\n",
        "# 데이터 Describe 해 보기\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(X)\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS7b2qL9KBJ8",
        "outputId": "25996cbf-5832-4b5b-ee66-523a06a22b39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Names: [0 1 2 3 4 5 6 7 8 9]\n",
            "           0            1            2            3            4   \\\n",
            "count  1797.0  1797.000000  1797.000000  1797.000000  1797.000000   \n",
            "mean      0.0     0.303840     5.204786    11.835838    11.848080   \n",
            "std       0.0     0.907192     4.754826     4.248842     4.287388   \n",
            "min       0.0     0.000000     0.000000     0.000000     0.000000   \n",
            "25%       0.0     0.000000     1.000000    10.000000    10.000000   \n",
            "50%       0.0     0.000000     4.000000    13.000000    13.000000   \n",
            "75%       0.0     0.000000     9.000000    15.000000    15.000000   \n",
            "max       0.0     8.000000    16.000000    16.000000    16.000000   \n",
            "\n",
            "                5            6            7            8            9   ...  \\\n",
            "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  ...   \n",
            "mean      5.781859     1.362270     0.129661     0.005565     1.993879  ...   \n",
            "std       5.666418     3.325775     1.037383     0.094222     3.196160  ...   \n",
            "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
            "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
            "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
            "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
            "max      16.000000    16.000000    15.000000     2.000000    16.000000  ...   \n",
            "\n",
            "                54           55           56           57           58  \\\n",
            "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000   \n",
            "mean      3.725097     0.206455     0.000556     0.279354     5.557596   \n",
            "std       4.919406     0.984401     0.023590     0.934302     5.103019   \n",
            "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
            "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
            "50%       1.000000     0.000000     0.000000     0.000000     4.000000   \n",
            "75%       7.000000     0.000000     0.000000     0.000000    10.000000   \n",
            "max      16.000000    13.000000     1.000000     9.000000    16.000000   \n",
            "\n",
            "                59           60           61           62           63  \n",
            "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  \n",
            "mean     12.089037    11.809126     6.764051     2.067891     0.364496  \n",
            "std       4.374694     4.933947     5.900623     4.090548     1.860122  \n",
            "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
            "25%      11.000000    10.000000     0.000000     0.000000     0.000000  \n",
            "50%      13.000000    14.000000     6.000000     0.000000     0.000000  \n",
            "75%      16.000000    16.000000    12.000000     2.000000     0.000000  \n",
            "max      16.000000    16.000000    16.000000    16.000000    16.000000  \n",
            "\n",
            "[8 rows x 64 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##4. train, test 데이터 분리\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "Ot6nORQ8KC2V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##5. 다양한 모델로 학습시켜보기\n",
        "\n",
        "# 모델 리스트\n",
        "models = [\n",
        "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
        "    (\"Random Forest\", RandomForestClassifier()),\n",
        "    (\"SVM\", SVC()),\n",
        "    (\"SGD Classifier\", SGDClassifier()),\n",
        "    (\"Logistic Regression\", LogisticRegression())\n",
        "]\n",
        "\n",
        "##6. 모델을 평가해 보기\n",
        "\n",
        "# 각 모델을 학습시키고 평가하기\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)  # 모델 학습\n",
        "    y_pred = model.predict(X_test)  # 예측\n",
        "    print(f\"{name} 모델 성능:\")\n",
        "    print(classification_report(y_test, y_pred))  # 성능 평가"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27zCfO4AKIwt",
        "outputId": "9172d735-45c8-4fbc-d8bf-78c9a720e488"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.89      0.93        53\n",
            "           1       0.79      0.76      0.78        50\n",
            "           2       0.76      0.81      0.78        47\n",
            "           3       0.80      0.81      0.81        54\n",
            "           4       0.88      0.85      0.86        60\n",
            "           5       0.92      0.86      0.89        66\n",
            "           6       0.88      0.94      0.91        53\n",
            "           7       0.78      0.85      0.82        55\n",
            "           8       0.78      0.84      0.81        43\n",
            "           9       0.89      0.85      0.87        59\n",
            "\n",
            "    accuracy                           0.85       540\n",
            "   macro avg       0.85      0.85      0.85       540\n",
            "weighted avg       0.85      0.85      0.85       540\n",
            "\n",
            "Random Forest 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        53\n",
            "           1       0.96      1.00      0.98        50\n",
            "           2       1.00      0.98      0.99        47\n",
            "           3       0.98      0.96      0.97        54\n",
            "           4       0.97      1.00      0.98        60\n",
            "           5       0.97      0.97      0.97        66\n",
            "           6       0.98      0.98      0.98        53\n",
            "           7       0.98      0.98      0.98        55\n",
            "           8       0.98      0.98      0.98        43\n",
            "           9       0.98      0.95      0.97        59\n",
            "\n",
            "    accuracy                           0.98       540\n",
            "   macro avg       0.98      0.98      0.98       540\n",
            "weighted avg       0.98      0.98      0.98       540\n",
            "\n",
            "SVM 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        53\n",
            "           1       1.00      1.00      1.00        50\n",
            "           2       1.00      1.00      1.00        47\n",
            "           3       0.98      0.98      0.98        54\n",
            "           4       1.00      1.00      1.00        60\n",
            "           5       1.00      0.98      0.99        66\n",
            "           6       0.98      1.00      0.99        53\n",
            "           7       0.98      0.98      0.98        55\n",
            "           8       0.95      0.98      0.97        43\n",
            "           9       0.97      0.95      0.96        59\n",
            "\n",
            "    accuracy                           0.99       540\n",
            "   macro avg       0.99      0.99      0.99       540\n",
            "weighted avg       0.99      0.99      0.99       540\n",
            "\n",
            "SGD Classifier 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        53\n",
            "           1       0.98      0.84      0.90        50\n",
            "           2       0.96      1.00      0.98        47\n",
            "           3       0.98      0.96      0.97        54\n",
            "           4       0.97      1.00      0.98        60\n",
            "           5       0.96      0.98      0.97        66\n",
            "           6       1.00      0.98      0.99        53\n",
            "           7       0.98      0.96      0.97        55\n",
            "           8       0.77      0.95      0.85        43\n",
            "           9       0.96      0.90      0.93        59\n",
            "\n",
            "    accuracy                           0.96       540\n",
            "   macro avg       0.96      0.95      0.95       540\n",
            "weighted avg       0.96      0.96      0.96       540\n",
            "\n",
            "Logistic Regression 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        53\n",
            "           1       0.94      0.94      0.94        50\n",
            "           2       0.96      0.98      0.97        47\n",
            "           3       0.98      0.96      0.97        54\n",
            "           4       1.00      0.97      0.98        60\n",
            "           5       0.94      0.94      0.94        66\n",
            "           6       0.96      0.98      0.97        53\n",
            "           7       0.98      0.96      0.97        55\n",
            "           8       0.91      0.98      0.94        43\n",
            "           9       0.97      0.95      0.96        59\n",
            "\n",
            "    accuracy                           0.96       540\n",
            "   macro avg       0.96      0.97      0.96       540\n",
            "weighted avg       0.97      0.96      0.96       540\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- SVM 모델은 정확도(0.99)와 정밀도, 재현율, F1-score 모두 거의 완벽한 점수를 기록하고 있다. SVM 모델이 이 6-1 실습에서는 가장 뛰어난 성능을 보인다.\n",
        "\n",
        "- Random Forest 모델은 모든 지표에서 매우 높은 성능을 보이고 있다. 특히 정확도(0.98)와 정밀도, 재현율, F1-score가 높은 수준을 유지하며, 상위 모델로 간주할 수 있을 것이다.\n",
        "\n",
        "- Decision Tree 모델은 다소 정확도(0.85)가 낮고, 일부 클래스에서 성능이 떨어지지만, 다른 모델에 비해 성능이 일정한 수준으로 유지되고 있다.\n",
        "\n",
        "- SGD Classifier와 Logistic Regression은 전반적으로 좋은 성능을 보이지만, 정확도와 F1-score에서 SVM보다는 떨어지는 것으로 보인다.\n"
      ],
      "metadata": {
        "id": "4VW6HdabLqoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6-2. 프로젝트 (2) load_wine : 와인을 분류해 봅시다"
      ],
      "metadata": {
        "id": "I9FVll-JLOvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##1. 필요한 모듈 import하기\n",
        "##2. 데이터 준비\n",
        "##3. 데이터 이해하기\n",
        "##4. train, test 데이터 분리\n",
        "##5. 다양한 모델로 학습시켜보기\n",
        "##6. 모델을 평가해 보기"
      ],
      "metadata": {
        "id": "d92RpfDfLSVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##1. 필요한 모듈 import하기\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression"
      ],
      "metadata": {
        "id": "rtJEAIz6LWta"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##2. 데이터 준비\n",
        "\n",
        "# load_wine로 데이터셋 불러오기\n",
        "wine = load_wine()\n",
        "\n",
        "# 데이터셋 내용 확인\n",
        "print(wine.data.shape)  # (178, 13): 178개의 샘플, 13개의 특성\n",
        "print(wine.target_names)  # 와인의 종류(3가지)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3TiDrWmM_7Z",
        "outputId": "20802a36-47b9-4ad4-c7cf-96de324d58aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 13)\n",
            "['class_0' 'class_1' 'class_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##3. 데이터 이해하기\n",
        "\n",
        "# Feature Data: 와인의 화학적 특성\n",
        "X = wine.data\n",
        "\n",
        "# Label Data: 와인의 종류(0, 1, 2)\n",
        "y = wine.target\n",
        "\n",
        "# Target Names 출력하기\n",
        "print(\"Target Names:\", wine.target_names)\n",
        "\n",
        "# 데이터 Describe 해 보기\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(X, columns=wine.feature_names)\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFiJeYbvNGMi",
        "outputId": "a3b70007-d60e-4ab4-a0d8-46024d911ba2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Names: ['class_0' 'class_1' 'class_2']\n",
            "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
            "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
            "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
            "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
            "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
            "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
            "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
            "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
            "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
            "\n",
            "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
            "count     178.000000  178.000000            178.000000       178.000000   \n",
            "mean        2.295112    2.029270              0.361854         1.590899   \n",
            "std         0.625851    0.998859              0.124453         0.572359   \n",
            "min         0.980000    0.340000              0.130000         0.410000   \n",
            "25%         1.742500    1.205000              0.270000         1.250000   \n",
            "50%         2.355000    2.135000              0.340000         1.555000   \n",
            "75%         2.800000    2.875000              0.437500         1.950000   \n",
            "max         3.880000    5.080000              0.660000         3.580000   \n",
            "\n",
            "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
            "count       178.000000  178.000000                    178.000000   178.000000  \n",
            "mean          5.058090    0.957449                      2.611685   746.893258  \n",
            "std           2.318286    0.228572                      0.709990   314.907474  \n",
            "min           1.280000    0.480000                      1.270000   278.000000  \n",
            "25%           3.220000    0.782500                      1.937500   500.500000  \n",
            "50%           4.690000    0.965000                      2.780000   673.500000  \n",
            "75%           6.200000    1.120000                      3.170000   985.000000  \n",
            "max          13.000000    1.710000                      4.000000  1680.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##4. train, test 데이터 분리\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "cm1ZV0k0NNOf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##5. 다양한 모델로 학습시켜보기\n",
        "\n",
        "# 모델 리스트\n",
        "models = [\n",
        "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
        "    (\"Random Forest\", RandomForestClassifier()),\n",
        "    (\"SVM\", SVC()),\n",
        "    (\"SGD Classifier\", SGDClassifier()),\n",
        "    (\"Logistic Regression\", LogisticRegression())\n",
        "]\n",
        "\n",
        "# 각 모델을 학습시키고 평가하기\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)  # 모델 학습\n",
        "    y_pred = model.predict(X_test)  # 예측\n",
        "    print(f\"{name} 모델 성능:\")\n",
        "    print(classification_report(y_test, y_pred))  # 성능 평가"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ynq1UgmNTPk",
        "outputId": "d487b00a-9211-451e-b54a-db64500d9617"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        19\n",
            "           1       0.95      1.00      0.98        21\n",
            "           2       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.96        54\n",
            "   macro avg       0.97      0.96      0.96        54\n",
            "weighted avg       0.96      0.96      0.96        54\n",
            "\n",
            "Random Forest 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        21\n",
            "           2       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           1.00        54\n",
            "   macro avg       1.00      1.00      1.00        54\n",
            "weighted avg       1.00      1.00      1.00        54\n",
            "\n",
            "SVM 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       0.63      0.90      0.75        21\n",
            "           2       0.60      0.21      0.32        14\n",
            "\n",
            "    accuracy                           0.76        54\n",
            "   macro avg       0.74      0.71      0.69        54\n",
            "weighted avg       0.75      0.76      0.72        54\n",
            "\n",
            "SGD Classifier 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.84        19\n",
            "           1       0.83      0.24      0.37        21\n",
            "           2       0.45      0.71      0.56        14\n",
            "\n",
            "    accuracy                           0.63        54\n",
            "   macro avg       0.67      0.65      0.59        54\n",
            "weighted avg       0.70      0.63      0.59        54\n",
            "\n",
            "Logistic Regression 모델 성능:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97        19\n",
            "           1       0.95      1.00      0.98        21\n",
            "           2       1.00      1.00      1.00        14\n",
            "\n",
            "    accuracy                           0.98        54\n",
            "   macro avg       0.98      0.98      0.98        54\n",
            "weighted avg       0.98      0.98      0.98        54\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Random Forest는 모든 지표에서 가장 우수한 성능을 보이며, 모든 클래스를 100% 정확하게 예측했다.\n",
        "- Logistic Regression도 우수한 성능을 보이지만, Class 2에서만 조금 더 좋은 성능을 보였다.\n",
        "- Decision Tree는 좋지만, Class 2에서 성능이 떨어지긴 했다.\n",
        "- SVM과 SGD Classifier는 성능이 상대적으로 떨어지며, 특히 Class 1과 Class 2에서 문제가 있었다.\n",
        "\n",
        "따라서, Random Forest 모델이 가장 적합한 모델로 보이며, SVM과 SGD Classifier는 개선이 필요하다."
      ],
      "metadata": {
        "id": "twgKM1H7N8kH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6-3. 프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 봅시다"
      ],
      "metadata": {
        "id": "85us4UPlPsve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##1. 필요한 모듈 import하기\n",
        "##2. 데이터 준비\n",
        "##3. 데이터 이해하기\n",
        "##4. train, test 데이터 분리\n",
        "##5. 다양한 모델로 학습시켜보기\n",
        "##6. 모델을 평가해 보기"
      ],
      "metadata": {
        "id": "-Udr4PxROzCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##1. 필요한 모듈 import하기\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "eB9QTVrbPwuZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##2. 데이터 준비\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # feature 데이터\n",
        "y = data.target  # label 데이터"
      ],
      "metadata": {
        "id": "zqMvnJgxP2mW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##3. 데이터 이해하기\n",
        "\n",
        "print(data.feature_names)  # 특성 이름 출력\n",
        "print(data.target_names)   # 라벨의 클래스(암/비암) 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVaHvvgQP3bI",
        "outputId": "f2471a42-5710-4210-c29f-cded61a1ae62"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "['malignant' 'benign']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##4. train, test 데이터 분리\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ctYH89kBP55Q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##5. 다양한 모델로 학습시켜보기\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "#SYM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "#SGD Classifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_model = SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred_sgd = sgd_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=10000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaYUCtb2P6uQ",
        "outputId": "7883ca6d-db84-4410-b697-43e4ab3491e7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90        43\n",
            "           1       0.94      0.93      0.94        71\n",
            "\n",
            "    accuracy                           0.92       114\n",
            "   macro avg       0.91      0.92      0.92       114\n",
            "weighted avg       0.92      0.92      0.92       114\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.93        43\n",
            "           1       0.92      1.00      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.74      0.85        43\n",
            "           1       0.87      1.00      0.93        71\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.93      0.87      0.89       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94        43\n",
            "           1       0.95      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "유방암 진단과 같은 중요한 의료 문제에서는 정밀도와 재현율이 모두 중요하다. 왜냐하면 정밀도가 낮으면 \"암이 아니라고 예측한 환자\" 중 일부가 사실 암이었을 수 있기 때문에, 암 환자에게 적절한 치료나 추적 검사를 제공하지 못할 위험이 있다.\n",
        "또한 재현율이 낮으면 \"실제로 암이 있는 환자\" 중 일부를 놓칠 수 있기 때문에, 암이 있는 사람을 발견하지 못하고 치료가 지연될 수 있기도 하다.\n",
        "따라서 F1-Score는 정밀도와 재현율의 균형을 잘 반영해주므로 이 지표가 중요하다. 그러므로 F1-Score가 높은 모델을 선택하는 것이 좋겠다.\n",
        "\n",
        "Random Forest 모델이 F1-Score와 정확도 면에서 가장 좋은 성능을 보였으므로, 이 모델을 최우선적으로 선택하는 것이 좋아보인다. Logistic Regression 모델도 좋은 성능을 보였지만, Random Forest가 더 우수한 성능을 보였다."
      ],
      "metadata": {
        "id": "qvx0XU6HQwl4"
      }
    }
  ]
}